deepspeed: ./config/deepspeed/zero2.json
version: plain
bf16: True
tf32: True
per_device_train_batch_size: 32
per_device_eval_batch_size: 4
gradient_accumulation_steps: 1
warmup_ratio: 0.03
lr_scheduler_type: cosine
learning_rate: 1e-3
weight_decay: 0.0
model_max_length: 2048
gradient_checkpointing: True
dataloader_num_workers: 4
report_to: wandb


defaults:
  - unfreeze: pretrain
  - learning_rate: default
  - weight_decay: default
